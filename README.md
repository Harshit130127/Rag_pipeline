# Retrieval-Augmented Generation (RAG) Prototype

This repository contains an experimental project exploring Retrieval-Augmented Generation (RAG) — a cutting-edge AI framework that enhances Large Language Models (LLMs) with external knowledge sources.

The goal of this project was to:

Understand how RAG integrates retrieval and generation components.

Implement document loading and preprocessing using LangChain.

Study embeddings, vector databases, and retrieval pipelines for real-world AI use cases.

## Current Status

This project is temporarily paused.
Development was started as part of a college seminar to explore RAG concepts and partial implementation (document loading stage).
Further modules (embeddings, retrievers, and QA chains) will be added in a future update.

## Tech Stack

Python

LangChain (Community Edition)

Jupyter Notebook / VS Code

FAISS / Vector Databases (planned)

## Note

This repository is now **archived** — it remains public for reference and learning.  
Future work may include:
- Embedding generation using OpenAI or HuggingFace models.  
- Retrieval and query-answering chain setup.  
- Integration with Flask/Django for a simple RAG web app.